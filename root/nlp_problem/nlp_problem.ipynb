{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>NLP_PROBLEM</h1>\n",
    "<h1>___________________________________</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Getting the data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # It will help to read the csv files and create the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the training and testing data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('V1.4_Training.csv')\n",
    "data_test = pd.read_csv('SubtaskA_Trial_Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>COMMENT</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>663_3</td>\n",
       "      <td>\"Please enable removing language code from the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>663_4</td>\n",
       "      <td>\"Note: in your .csproj file, there is a Suppor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>664_1</td>\n",
       "      <td>\"Wich means the new version not fully replaced...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>664_2</td>\n",
       "      <td>\"Some of my users will still receive the old x...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>664_3</td>\n",
       "      <td>\"The store randomly gives the old xap or the n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                            COMMENT  LABEL\n",
       "0  663_3  \"Please enable removing language code from the...      1\n",
       "1  663_4  \"Note: in your .csproj file, there is a Suppor...      0\n",
       "2  664_1  \"Wich means the new version not fully replaced...      0\n",
       "3  664_2  \"Some of my users will still receive the old x...      0\n",
       "4  664_3  \"The store randomly gives the old xap or the n...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13101</td>\n",
       "      <td>\"I'm not asking Microsoft to Gives permission ...</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13121</td>\n",
       "      <td>\"somewhere between Android and iPhone.\"</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13131</td>\n",
       "      <td>\"And in the Windows Store you can flag the App...</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13132</td>\n",
       "      <td>\"Many thanks Sameh Hi, As we know, there is a ...</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13133</td>\n",
       "      <td>\"The idea is that we can develop a regular app...</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                            comment label\n",
       "0  13101  \"I'm not asking Microsoft to Gives permission ...     X\n",
       "1  13121            \"somewhere between Android and iPhone.\"     X\n",
       "2  13131  \"And in the Windows Store you can flag the App...     X\n",
       "3  13132  \"Many thanks Sameh Hi, As we know, there is a ...     X\n",
       "4  13133  \"The idea is that we can develop a regular app...     X"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving all the rows and the first index(TEXT DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = data.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appending all the training text data to a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = []\n",
    "for line in df1:\n",
    "    train_x.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting all the rows and second index(LABELS) and saving them to a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = data.iloc[:, 2]\n",
    "train_y = []\n",
    "for line in df2:\n",
    "    train_y.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = []\n",
    "df3 = data_test.iloc[:, 1]\n",
    "for line in df3:\n",
    "    test_x.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The given \"SubtaskA_Trial_Test_Labeled.csv\" has some errors so, copied it the column containing the labels and pasted it to a test file then it is read through all labels and saved it to a list as int\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_label.txt', 'r') as f:\n",
    "    test_y_file = f.readlines()\n",
    "\n",
    "test_y = []\n",
    "for val in test_y_file:\n",
    "    test_y.append(val[0])\n",
    "for index, val in enumerate(test_y):\n",
    "    val = int(val)\n",
    "    test_y[index] = val\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the length of training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-set size:  8500\n",
      "Test-set size:  592\n"
     ]
    }
   ],
   "source": [
    "print(\"Train-set size: \", len(train_x))\n",
    "print(\"Test-set size: \", len(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"The wp7 xap works only on WP7 and the wp8 xap works only for WP8.\"\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "index = 6\n",
    "print(train_x[index])\n",
    "print(train_y[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Text Preprocessing</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text data contains uppercase letters, numbers and punctuations. Having these makes the vocabulary go high unnecessarily which is bad for our model. So here the text data is <b>lowered</b>, <b>removed numbers</b>, <b>removed punctuations</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index ,line in enumerate(train_x):\n",
    "    line = line.lower() #lowercase lines\n",
    "    line = re.sub(r'\\d+', '', line) #regular expression to remove the numbers\n",
    "    translation = str.maketrans(\" \",\" \", string.punctuation)\n",
    "    line = line.translate(string.punctuation) #removes the punctuations\n",
    "    line = line.translate(translation)\n",
    "    train_x[index] = line # update the text files\n",
    "    \n",
    "for index ,line in enumerate(test_x):\n",
    "    line = line.lower()\n",
    "    line = re.sub(r'\\d+', '', line)\n",
    "    translation = str.maketrans(\" \",\" \", string.punctuation)\n",
    "    line = line.translate(string.punctuation)\n",
    "    line = line.translate(translation)\n",
    "    test_x[index] = line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the text is lowered, having numbers and punctuations removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the wp xap works only on wp and the wp xap works only for wp\n",
      "why not let us have several pages that we can put tiles on and name whatever we want to \n"
     ]
    }
   ],
   "source": [
    "index = 6\n",
    "print(train_x[index])\n",
    "print(test_x[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Designing the model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to import several things from Keras.\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, GRU,LSTM, Embedding\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>TOKENIZER</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the model accepts only numerical values we need to translate the text. So we tokenize the text to arrays with numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 2000 # setting the max number of words = vocabulary\n",
    "tokenizer = Tokenizer(num_words = num_words) # creating the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text = train_x + test_x # creating our tokenizer with the entire dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 253 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "tokenizer.fit_on_texts(data_text) # fitting the tokenizer to data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the tokenizer is ready, we convert the text to tokens using texts_to_sequences method in tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_tokens = tokenizer.texts_to_sequences(train_x) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the original text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my app has a wp version and a wp version xap in the same submission'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the tokenized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 31,  14,  64,   3,  81, 128,   4,   3,  81, 128, 802,   5,   1,\n",
       "        91, 672])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_x_tokens[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_tokens = tokenizer.texts_to_sequences(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'please add this simple and extremely helpful feature'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 46,  47,  13, 291,   4, 945, 624, 133])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(test_x_tokens[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is needed to set the length of the input array. To find this we find the max length and the avg length of and compute the length of our input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = [len(tokens) for tokens in train_x_tokens + test_x_tokens]\n",
    "num_tokens = np.array(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.67410910690717"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "# The max number of tokens is set to the average plus 2 standard deviations\n",
    "max_tokens = np.mean(num_tokens)+ 2 * np.std(num_tokens)\n",
    "\n",
    "#Converting the value to int\n",
    "max_tokens = int(max_tokens)\n",
    "print(max_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now <b>pad the tokenized data</b>. Why? Cause differenet sentences have different lengths but our input length to the model is fixed so we need to pad the text to make it the same length as of the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad = 'pre' # add 0's to the first places of the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_pad = pad_sequences(train_x_tokens, maxlen = max_tokens, padding= pad, truncating = pad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the sentences having length less than the input is padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  33,    1,  205, ...,   43,    6,  472],\n",
       "       [   0,  649,    5, ...,   16, 1534,    4],\n",
       "       [   0,    0,    0, ...,   97, 1028,  557],\n",
       "       ...,\n",
       "       [   0,    0,    0, ..., 1757,    2,   39],\n",
       "       [   0,    0,    0, ...,    3,  169,  633],\n",
       "       [   0,    0,    0, ...,    8,  207,  148]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_pad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly we pad the test sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_pad = pad_sequences(test_x_tokens, maxlen=max_tokens , padding = pad, truncating = pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer Inverse Map\n",
    "#  a function that will translate the integer-tokens back to words\n",
    "\n",
    "idx = tokenizer.word_index\n",
    "inverse_map = dict(zip(idx.values(), idx.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for converting a list of tokends back to a string of words\n",
    "\n",
    "def tokens_to_string(tokens):\n",
    "    # Map from tokens back to the words:\n",
    "    words = [inverse_map[token] for token in tokens if token != 0]\n",
    "    \n",
    "    #Concatenate all the words\n",
    "    text = \" \".join(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my app has a wp version and a wp version xap in the same submission'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my app has a wp version and a wp version xap in the same submission'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_to_string(train_x_tokens[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Deep Learning Model</h1>\n",
    "<br>\n",
    "Here the first layer is <b>Embedding</b> layer which normalizes the tokens then a <b>LSTM</b> layer which returns a sequence to a <b>GRU</b> layer. Why? after experimenting with diffenent combinations this one found out to give best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Embedding(input_dim = num_words, output_dim = embedding_size\n",
    "                    , input_length = max_tokens, name = 'layer_embedding'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(LSTM(8, return_sequences = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(GRU(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer_embedding (Embedding)  (None, 36, 8)             16000     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 36, 8)             544       \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 4)                 156       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 16,705\n",
      "Trainable params: 16,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(lr=1e-3)\n",
    "model.compile(loss ='binary_crossentropy', optimizer =  optimizer, metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the model gives an accuracy about 85%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8075 samples, validate on 425 samples\n",
      "Epoch 1/7\n",
      "8075/8075 [==============================] - 3s 419us/step - loss: 0.2747 - acc: 0.8899 - val_loss: 0.1386 - val_acc: 0.9553\n",
      "Epoch 2/7\n",
      "8075/8075 [==============================] - 4s 435us/step - loss: 0.2499 - acc: 0.9029 - val_loss: 0.1541 - val_acc: 0.9529\n",
      "Epoch 3/7\n",
      "8075/8075 [==============================] - 4s 554us/step - loss: 0.2301 - acc: 0.9134 - val_loss: 0.1118 - val_acc: 0.9600\n",
      "Epoch 4/7\n",
      "8075/8075 [==============================] - 4s 528us/step - loss: 0.2163 - acc: 0.9207 - val_loss: 0.1260 - val_acc: 0.9529\n",
      "Epoch 5/7\n",
      "8075/8075 [==============================] - 5s 584us/step - loss: 0.2008 - acc: 0.9293 - val_loss: 0.1154 - val_acc: 0.9576\n",
      "Epoch 6/7\n",
      "8075/8075 [==============================] - 5s 605us/step - loss: 0.1897 - acc: 0.9337 - val_loss: 0.1272 - val_acc: 0.9553\n",
      "Epoch 7/7\n",
      "8075/8075 [==============================] - 5s 624us/step - loss: 0.1873 - acc: 0.9345 - val_loss: 0.1665 - val_acc: 0.9341\n",
      "Wall time: 30.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1847afd4f98>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(train_x_pad, train_y, validation_split = 0.05, epochs =7, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/592 [==============================] - 0s 174us/step\n",
      "Wall time: 105 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = model.evaluate(test_x_pad, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the accuracy on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 76.18%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy : {0:.2%}\".format(result[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we give our own data to test our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"Please add this simple and extremely useful feature \"\n",
    "text2 = \"This is awesome\"\n",
    "text3 = \"you should develop an app to count the time\"\n",
    "\n",
    "texts = [text1,text2,text3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the text to integer tokens because that is what our machine demands\n",
    "tokens = tokenizer.texts_to_sequences(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding out input so that it gonna be of the same length\n",
    "tokens_pad = pad_sequences(tokens, maxlen=max_tokens, padding = pad, truncating= pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 36)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_pad.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_out = model.predict(tokens_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8149213 ]\n",
      " [0.06187698]\n",
      " [0.6954872 ]]\n"
     ]
    }
   ],
   "source": [
    "print(model_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Evaluation Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = pd.read_csv('SubtaskA_EvaluationData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>9566</th>\n",
       "      <th>This would enable live traffic aware apps.</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9569</td>\n",
       "      <td>Please try other formatting like bold italics ...</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9576</td>\n",
       "      <td>Since computers were invented to save time I s...</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9577</td>\n",
       "      <td>Allow rearranging if the user wants to change ...</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9579</td>\n",
       "      <td>Add SIMD instructions for better use of ARM NE...</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9580</td>\n",
       "      <td>Also using a hot swapping code generator (opti...</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   9566         This would enable live traffic aware apps.  X\n",
       "0  9569  Please try other formatting like bold italics ...  X\n",
       "1  9576  Since computers were invented to save time I s...  X\n",
       "2  9577  Allow rearranging if the user wants to change ...  X\n",
       "3  9579  Add SIMD instructions for better use of ARM NE...  X\n",
       "4  9580  Also using a hot swapping code generator (opti...  X"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data_text = eval_data.iloc[:,1]\n",
    "eval_text = []\n",
    "for text in eval_data_text:\n",
    "    eval_text.append(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index ,line in enumerate(eval_text):\n",
    "    line = line.lower() #lowercase lines\n",
    "    line = re.sub(r'\\d+', '', line) #regular expression to remove the numbers\n",
    "    translation = str.maketrans(\" \",\" \", string.punctuation)\n",
    "    line = line.translate(string.punctuation) #removes the punctuations\n",
    "    line = line.translate(translation)\n",
    "    train_x[index] = line # update the text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(eval_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_tokens = tokenizer.texts_to_sequences(eval_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_pad = pad_sequences(eval_tokens, maxlen = max_tokens, padding= pad, truncating = pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = []\n",
    "evaluation = model.predict(eval_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, val in enumerate(evaluation):\n",
    "    if val>0.5:\n",
    "        evaluation[index] = 1\n",
    "    else:\n",
    "        evaluation[index] = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dataframe to save the outputs and exporting to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_submission = eval_data.iloc[:, [0,1]]\n",
    "eval_output = pd.DataFrame(evaluation)\n",
    "result = pd.concat([eval_submission,eval_output], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(r'Soumyajit_Rout.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>___________________________________________________</h1>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
